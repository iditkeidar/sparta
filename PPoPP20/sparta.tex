\documentclass[sigplan,10pt,review,anonymous]{acmart}
\settopmatter{printfolios=true,printccs=false,printacmref=false}


\acmConference[PPoPP'20]{PPoPP 2019: 25th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming}{2020}{San Diego, CA, USA}
\acmYear{2020}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\setcopyright{none}
\bibliographystyle{ACM-Reference-Format}


%\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{color}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url}
\usepackage{multicol}
\usepackage{booktabs} % For formal tables
\usepackage{times}



\usepackage{multicol}
\input{macros}

\newcommand{\alg}{Sparta}  
\newcommand{\inred}[1]{{\color{red}{#1}}}
\newcommand{\inblue}[1]{{\color{blue}{#1}}}
\newcommand{\remove}[1]{}
\newcommand{\bigdataset}[1]{#1} % remove for now, add later


% ****************** TITLE ****************************************

\title{Scalable Top-K Retrieval}

%\titlerunning{Dummy short title}%optional, please use if title is longer than one line

\author{Gali Sheffi}%{Yahoo Research, Oath}{gsheffi@oath.com}{}{}
\author{Dmitry Basin}%{Yahoo Research, Oath}{dbasin@oath.com}{}{}
\author{Edward Bortnikov}%{Yahoo Research, Oath}{ebortnik@oath.com}{}{}
\author{David Carmel}%{Amazon}{david.carmel@gmail.com}{}{}
\author{Idit Keidar}%{Technion and Yahoo Research, Oath}{idish@ee.technion.ac.il}{}{}


\begin{document}


\begin{abstract}



Big data processing applications often rely on a \emph{top-k retrieval} building block, which selects (or approximates) the $k$ highest scoring data items based on an 
aggregation of features. For example, in a web search query with $n$ search terms, a document's score is the sum 
of its partial scores for the $n$ terms. Top-k  retrieval is typically used to sift through massive amounts of data and identify a smaller subset of it for 
further (more detailed) analysis. Because it filters out the bulk of the data, despite its relative simplicity, the top-k retrieval stage constitutes the main performance bottleneck.  

Beyond the rise in data  sizes, today's 
data processing scenarios also increase the number of features the score is computed over. 
% challenging existing top-k algorithms. 
In web search, for example, %top-k document retrieval is emerging as a performance bottleneck in query processing, as 
verbose queries are becoming mainstream,  
while state-of-the-art algorithms fail to process  long queries in real time. To date, attempts to
accelerate top-k retrieval via 
%approximate result computation and 
intra-query parallelism have produced limited results. 

We present \alg\ -- a practical parallel algorithm that exploits multi-core hardware for (approximate) top-k retrieval 
with interactive latency bounds. %Its design is inspired by  Fagin et al.'s seminal Threshold Algorithm for  aggregation in databases. 
Thanks to lightweight coordination and context sharing among concurrent threads,
\alg\ scales both in the number of query terms and in the searched index size. 
For example, on the 50M-document public ClueWeb09B 
dataset, \alg\  processes $12$-term queries \inred{twice} as fast as  the state-of-the-art. 
On a tenfold  bigger index, 
\alg\ continues to process queries at the same speed, whereas existing algorithms 
\inred{deteriorate significantly}.
%\alg\ further significantly improves the overall system throughput for workloads abundant with verbose queries  
%on production-motivated query mixes. 
\end{abstract}

% \keywords{Parallel computing, multi-threading, information retrieval, web-search, top-k}%mandatory in camera-ready

\maketitle

\input{intro}
\input{Background}
\input{algorithm}
\input{evaluation}
\input{related}
\input{conclusions}

\clearpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}  


\end{document}
