\documentclass[sigplan,10pt,review,anonymous]{acmart}
\settopmatter{printfolios=true,printccs=false,printacmref=false}


\acmConference[PPoPP'20]{PPoPP 2019: 25th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming}{2020}{San Diego, CA, USA}
\acmYear{2020}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\setcopyright{none}
\bibliographystyle{ACM-Reference-Format}


%\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{color}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url}
\usepackage{multicol}
\usepackage{booktabs} % For formal tables
\usepackage{times}



\usepackage{multicol}
\input{macros}

\newcommand{\alg}{Sparta}  
\newcommand{\inred}[1]{{\color{red}{#1}}}
\newcommand{\inblue}[1]{{\color{blue}{#1}}}
\newcommand{\remove}[1]{}
\newcommand{\bigdataset}[1]{#1} % remove for now, add later


% ****************** TITLE ****************************************

\title{Scalable Top-K Retrieval with \alg}

%\titlerunning{Dummy short title}%optional, please use if title is longer than one line

\author{Gali Sheffi}%{Yahoo Research, Oath}{gsheffi@oath.com}{}{}
\author{Dmitry Basin}%{Yahoo Research, Oath}{dbasin@oath.com}{}{}
\author{Edward Bortnikov}%{Yahoo Research, Oath}{ebortnik@oath.com}{}{}
\author{David Carmel}%{Amazon}{david.carmel@gmail.com}{}{}
\author{Idit Keidar}%{Technion and Yahoo Research, Oath}{idish@ee.technion.ac.il}{}{}


\begin{document}


\begin{abstract}


Many big data processing applications rely on a \emph{top-k retrieval} building block, which selects (or approximates) the $k$ highest-scoring data items based on an aggregation of features. 
In web search, for instance, a document's score is the sum of its scores for all query terms. Top-k retrieval is often used to sift through massive data and identify a smaller subset of it for further  analysis. Because it filters out the bulk of the data, 
%despite its relative simplicity, 
it often constitutes the main performance bottleneck.  

Beyond the rise in data sizes, today's data processing scenarios also increase the number of features contributing to the overall score. 
In web search, for example, 
verbose queries are becoming mainstream,  
while state-of-the-art algorithms fail to process long queries in real-time. 


We present \alg, a practical parallel algorithm that exploits multi-core hardware for fast (approximate) top-k retrieval. 
Thanks to lightweight coordination and judicious context sharing among threads,
\alg\ scales both in the number of features and in the searched index size. 
In our web search case study on 
50M documents, \alg\  processes $12$-term queries more than twice as fast as the state-of-the-art. 
On a tenfold  bigger index, 
\alg\ processes queries at the same speed, whereas the average latency of 
existing algorithms soars to be an order-of-magnitude larger than \alg's.
\end{abstract}

% \keywords{Parallel computing, multi-threading, information retrieval, web-search, top-k}%mandatory in camera-ready



\maketitle

\input{intro}
\input{Background}
\input{algorithm}
\input{evaluation}
\input{related}
\input{conclusions}

\clearpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}  


\end{document}
