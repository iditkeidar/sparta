\documentclass[sigplan,10pt,review,anonymous]{acmart}
\settopmatter{printfolios=true,printccs=false,printacmref=false}


\acmConference[PPoPP'20]{PPoPP 2019: 25th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming}{2020}{San Diego, CA, USA}
\acmYear{2020}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\setcopyright{none}
\bibliographystyle{ACM-Reference-Format}


%\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{color}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url}
\usepackage{multicol}
\usepackage{booktabs} % For formal tables
\usepackage{times}



\usepackage{multicol}
\input{macros}

\newcommand{\alg}{Sparta}  
\newcommand{\inred}[1]{{\color{red}{#1}}}
\newcommand{\inblue}[1]{{\color{blue}{#1}}}
\newcommand{\remove}[1]{}
\newcommand{\bigdataset}[1]{#1} % remove for now, add later


% ****************** TITLE ****************************************

\title{Fast Parallel Top-K Retrieval of Verbose Queries}

%\titlerunning{Dummy short title}%optional, please use if title is longer than one line

\author{Gali Sheffi}%{Yahoo Research, Oath}{gsheffi@oath.com}{}{}
\author{Dmitry Basin}%{Yahoo Research, Oath}{dbasin@oath.com}{}{}
\author{Edward Bortnikov}%{Yahoo Research, Oath}{ebortnik@oath.com}{}{}
\author{David Carmel}%{Amazon}{david.carmel@gmail.com}{}{}
\author{Idit Keidar}%{Technion and Yahoo Research, Oath}{idish@ee.technion.ac.il}{}{}


\begin{document}


\begin{abstract}



Many big data processing applications rely on a \emph{top-k retrieval} building block, which identifies the $k$ highest scoring data items based on an 
aggregation of attributes. For example, in the context of web search, a query is comprised of a list of $n$ search terms, and a document's score is computed as the sum 
of its partial scores on the $n$ terms. Top-k query retrieval is typically used to sift through massive amounts of data and identify a smaller set of data items for 
further (more complex) analysis. Thus, its scalability is crucial for overall performance. Modern use-cases increase the number of attributes the score is computed over, 
which challenges existing top-k algorithms. 
For example, in web search, top-k document retrieval is emerging as a performance bottleneck in query processing, as verbose queries are becoming 
mainstream, while state-of-the-art algorithms fail to process such long queries in real time. To date, attempts to
accelerate top-k evaluation via approximate result computation and intra-query parallelism have produced limited results. 

We present \alg\ -- a practical parallel algorithm that exploits multi-core hardware to run approximate top-k retrieval 
within interactive latency bounds. Its design is inspired by  Fagin et al.'s seminal Threshold Algorithm for  aggregation in databases. 
\alg\ scales through lightweight coordination and context sharing among concurrent threads,  
both in the number of query terms and in the searched index size. 
For example, when applied to the 50M-document public ClueWeb09B 
dataset, \alg\  processes $12$-term queries $3.6$ times faster than the state-of-the-art. 
On a tenfold  bigger index, 
\alg\ continues to process queries at the same speed, whereas today's best-in-class algorithm is more than 60 times slower. 
\alg\ further significantly improves the overall system throughput for workloads abundant with verbose queries  
on production-motivated query mixes. 
\end{abstract}

% \keywords{Parallel computing, multi-threading, information retrieval, web-search, top-k}%mandatory in camera-ready

\maketitle

\input{intro}
\input{Background}
\input{algorithm}
\input{evaluation}
\input{related}
\input{conclusions}

\clearpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}  


\end{document}
